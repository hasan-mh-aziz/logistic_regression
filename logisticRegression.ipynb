{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import eig\n",
    "from numpy.linalg import inv,pinv\n",
    "import pandas as pd\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import math\n",
    "%run common_functions.ipynb\n",
    "%run naive_bayes_classifier.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, lr=0.1, max_iter=5000, cost_thresold = 0.001, fit_intercept=True, verbose=False):\n",
    "        self.lr = lr\n",
    "        self.max_iter = max_iter\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.verbose = verbose\n",
    "        self.cost_thresold = cost_thresold\n",
    "    \n",
    "    def add_intercept(self, X):\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        return np.concatenate((intercept, X), axis=1)\n",
    "    \n",
    "    def getZ(self, x, theta):\n",
    "        return np.dot(x, theta.T)\n",
    "    \n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        return 1/(1+np.exp(-z))\n",
    "    \n",
    "    \n",
    "    def getCost(self, theta, X, y):\n",
    "        m = len(y)\n",
    "        sigma = self.sigmoid(self.getZ(X, theta))\n",
    "        positive_loss = np.multiply(y, np.log(sigma))\n",
    "        negative_loss = np.multiply(1 - y, np.log(1 - sigma))\n",
    "        return -np.mean(positive_loss + negative_loss)\n",
    "\n",
    "\n",
    "    def getGradients(self, theta, X, y):\n",
    "        m = len(y)\n",
    "        temp = self.sigmoid(self.getZ(X, theta)) - y\n",
    "        return (1 / m) * np.dot(X.T, temp)\n",
    "    \n",
    "    \n",
    "    def gradientDescent(self, class_index, X, y):\n",
    "        class_theta = self.theta[class_index]\n",
    "        costs = []\n",
    "\n",
    "        for iteration in range(self.max_iter):\n",
    "            currentGradient = self.getGradients(class_theta, X, y)\n",
    "            currentCost = self.getCost(class_theta, X, y)\n",
    "            class_theta -= self.lr * currentGradient\n",
    "            costs.append(currentCost)\n",
    "            \n",
    "            if(self.verbose == True and iteration % 1000 == 0):\n",
    "                print(f'loss: {self.getCost(class_theta, X, y)} \\t')\n",
    "                \n",
    "            if abs(currentCost) < self.cost_thresold:\n",
    "                if(self.verbose == True):\n",
    "                    print(\"loop broke by thresold\")\n",
    "                break\n",
    "\n",
    "        return costs, class_theta\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        if self.fit_intercept:\n",
    "            X = self.add_intercept(X)\n",
    "            \n",
    "        (m, n) = X.shape\n",
    "        self.classes = np.unique(y)\n",
    "        k = len(self.classes)\n",
    "        self.theta = np.zeros((k, n)) #weights initialization\n",
    "        class_costs = {}\n",
    "\n",
    "#         Initial call to print 0% progress\n",
    "        printProgressBar(0, k, prefix = 'Logistic Regression Progress:', suffix = 'Complete', length = 50)\n",
    "        \n",
    "        for class_index in range(k):\n",
    "            printProgressBar(class_index + 1, k, prefix = 'Logistic Regression Progress:', suffix = 'Complete', length = 50)\n",
    "            if(self.verbose == True):\n",
    "                print(self.classes[class_index])\n",
    "            binary_class = (y == class_index).flatten()\n",
    "            costs, self.theta[class_index] = self.gradientDescent(class_index, X, binary_class)\n",
    "            class_costs[class_index] = costs\n",
    "            \n",
    "        return class_costs\n",
    "\n",
    "    \n",
    "    def predict(self, X, y):\n",
    "        if self.fit_intercept:\n",
    "            X = self.add_intercept(X)\n",
    "\n",
    "#         predictions = self.classes[np.argmax(X @ self.theta.T, axis = 1)]\n",
    "        all_z = self.getZ(X, self.theta)\n",
    "        predictions = self.classes[np.argmax(self.sigmoid(all_z), axis = 1)]\n",
    "        accuracy = np.mean(predictions == y.flatten()) * 100\n",
    "        \n",
    "        return accuracy, predictions   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
