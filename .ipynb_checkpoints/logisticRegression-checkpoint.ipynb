{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import eig\n",
    "from numpy.linalg import inv,pinv\n",
    "import pandas as pd\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import math\n",
    "%run common_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, lr=0.1, max_iter=5000, cost_thresold = 0.001, fit_intercept=True, verbose=False):\n",
    "        self.lr = lr\n",
    "        self.max_iter = max_iter\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.verbose = verbose\n",
    "        self.cost_thresold = cost_thresold\n",
    "    \n",
    "    def add_intercept(self, X):\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        return np.concatenate((intercept, X), axis=1)\n",
    "    \n",
    "    def getZ(self, x, theta):\n",
    "        return np.dot(x, theta.T)\n",
    "    \n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        return 1/(1+np.exp(-z))\n",
    "    \n",
    "    \n",
    "    def getCost(self, theta, X, y):\n",
    "        m = len(y)\n",
    "        sigma = self.sigmoid(self.getZ(X, theta))\n",
    "        positive_loss = np.multiply(y, np.log(sigma))\n",
    "        negative_loss = np.multiply(1 - y, np.log(1 - sigma))\n",
    "        return -np.mean(positive_loss + negative_loss)\n",
    "\n",
    "\n",
    "    def getGradients(self, theta, X, y):\n",
    "        m = len(y)\n",
    "        temp = self.sigmoid(self.getZ(X, theta)) - y\n",
    "        return (1 / m) * np.dot(X.T, temp)\n",
    "    \n",
    "    \n",
    "    def gradientDescent(self, class_index, X, y):\n",
    "        class_theta = self.theta[class_index]\n",
    "        costs = []\n",
    "\n",
    "        for iteration in range(self.max_iter):\n",
    "            currentGradient = self.getGradients(class_theta, X, y)\n",
    "            currentCost = self.getCost(class_theta, X, y)\n",
    "            class_theta -= self.lr * currentGradient\n",
    "            costs.append(currentCost)\n",
    "            \n",
    "            if(self.verbose == True and iteration % 1000 == 0):\n",
    "                print(f'loss: {self.getCost(class_theta, X, y)} \\t')\n",
    "                \n",
    "            if abs(currentCost) < self.cost_thresold:\n",
    "                if(self.verbose == True):\n",
    "                    print(\"loop broke by thresold\")\n",
    "                break\n",
    "\n",
    "        return costs, class_theta\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        if self.fit_intercept:\n",
    "            X = self.add_intercept(X)\n",
    "            \n",
    "        (m, n) = X.shape\n",
    "        self.classes = np.unique(y)\n",
    "        k = len(self.classes)\n",
    "        self.theta = np.zeros((k, n)) #weights initialization\n",
    "        class_costs = {}\n",
    "\n",
    "#         Initial call to print 0% progress\n",
    "        printProgressBar(0, k, prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
    "        \n",
    "        for class_index in range(k):\n",
    "            printProgressBar(class_index + 1, k, prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
    "            if(self.verbose == True):\n",
    "                print(self.classes[class_index])\n",
    "            binary_class = (y == class_index).flatten()\n",
    "            costs, self.theta[class_index] = self.gradientDescent(class_index, X, binary_class)\n",
    "            class_costs[class_index] = costs\n",
    "            \n",
    "        return class_costs\n",
    "\n",
    "    \n",
    "    def predict(self, X, y):\n",
    "        if self.fit_intercept:\n",
    "            X = self.add_intercept(X)\n",
    "\n",
    "        predictions = self.classes[np.argmax(X @ self.theta.T, axis = 1)]\n",
    "        accuracy = np.mean(predictions == y.flatten()) * 100\n",
    "        \n",
    "        return accuracy, predictions   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  (1797, 64)\n",
      "y:  (1797, 1)\n",
      "[0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]\n"
     ]
    }
   ],
   "source": [
    "with open('digits.csv', 'r') as csvfile:\n",
    "    digitDataset = np.asarray(list(csv.reader(csvfile, quoting=csv.QUOTE_NONNUMERIC)))\n",
    "    \n",
    "x = digitDataset[:, :-1]\n",
    "y = digitDataset[:, -1:]\n",
    "print(\"x: \", x.shape)\n",
    "print(\"y: \", y.shape)\n",
    "print(np.unique(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Progress: |--------------------------------------------------| 0.0% Complete\r",
      "\r",
      "Progress: |█████---------------------------------------------| 10.0% Complete\r",
      "\r",
      "Progress: |██████████----------------------------------------| 20.0% Complete\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hasan/Installations/miniconda3/envs/AML/lib/python3.7/site-packages/ipykernel_launcher.py:25: RuntimeWarning: divide by zero encountered in log\n",
      "/home/hasan/Installations/miniconda3/envs/AML/lib/python3.7/site-packages/ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete\n",
      "   Train errors(%)  Test errors(%)\n",
      "0          1.32128        3.899721\n"
     ]
    }
   ],
   "source": [
    "lg = LogisticRegression()\n",
    "k_folded_train_indices, k_folded_test_indices = get_k_fold_indices(k, y.shape[0], shuffle=True)\n",
    "\n",
    "folds_errors = []\n",
    "\n",
    "# for fold, train_indices in enumerate(k_folded_train_indices):\n",
    "#     print(f'Fold#{fold + 1} of {k}:')\n",
    "#     test_indices = k_folded_test_indices[fold]\n",
    "    \n",
    "#     train_x = x[train_indices]\n",
    "#     test_x = x[test_indices]\n",
    "#     train_y = y[train_indices]\n",
    "#     test_y = y[test_indices]\n",
    "    \n",
    "#     class_costs = lg.fit(train_x, train_y)\n",
    "\n",
    "#     train_accuracy, train_predictions = lg.predict(train_x, train_y)\n",
    "#     test_accuracy, test_predictions = lg.predict(test_x, test_y)\n",
    "# #     print(train_accuracy)\n",
    "#     folds_errors.append([100 - train_accuracy, 100 - test_accuracy])\n",
    "\n",
    "# # print(all_projected_test_features)\n",
    "# errors_df = pd.DataFrame(folds_errors, columns = [\"Train errors(%)\", \"Test errors(%)\"])\n",
    "# print(errors_df)\n",
    "\n",
    "train_indices, test_indices = get_train_test_indices_by_train_percentage(80, y.shape[0], shuffle=True)\n",
    "train_x = x[train_indices]\n",
    "test_x = x[test_indices]\n",
    "train_y = y[train_indices]\n",
    "test_y = y[test_indices]\n",
    "\n",
    "class_costs = lg.fit(train_x, train_y)\n",
    "\n",
    "split_train_accuracy, split_train_predictions = lg.predict(train_x, train_y)\n",
    "split_test_accuracy, split_test_accuracy = lg.predict(test_x, test_y)\n",
    "split_errors = [[100 - split_train_accuracy, 100 - split_test_accuracy]]\n",
    "\n",
    "split_errors_df = pd.DataFrame(split_errors, columns = [\"Train errors(%)\", \"Test errors(%)\"])\n",
    "print(split_errors_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
