{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.io.parsers.read_csv(\n",
    "    filepath_or_buffer='digits.csv',\n",
    "    header=None,\n",
    "    sep=',',\n",
    "    )\n",
    "\n",
    "data_group = df.groupby(df.iloc[:,-1])\n",
    "df.insert(0, \"-1\", np.ones((df.shape[0],), dtype=int), True) \n",
    "original_df = pd.io.parsers.read_csv(\n",
    "    filepath_or_buffer='digits.csv',\n",
    "    header=None,\n",
    "    sep=',',\n",
    "    )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic methods\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def get_cost(theta, x, y):\n",
    "    sigm = sigmoid(x @ theta)\n",
    "    cost = 1 / len(y) * np.sum(-y * np.log(sigm) - (1 - y) * np.log(1 - sigm))\n",
    "    return cost\n",
    "def get_gradient(theta, x , y):\n",
    "    return 1 / len(y) * ((y - sigmoid(x @ theta)) @ x)\n",
    "def fit(x, y, iteration_count=500, learn_rate=0.1):\n",
    "    thetas = []\n",
    "    costs = np.zeros(iteration_count)\n",
    "    for target_class in classes:\n",
    "        theta = np.zeros(x.shape[1])\n",
    "        target_class_val = np.where(y == target_class, 1, 0)\n",
    "        for iteration_n in range(iteration_count):\n",
    "            costs[iteration_n]= get_cost(theta, x, target_class_val)\n",
    "            gradient = get_gradient(theta, x, target_class_val)\n",
    "            theta += learn_rate * gradient\n",
    "            \n",
    "        thetas.append(theta)\n",
    "    return thetas, costs\n",
    "\n",
    "def predict(classes, thetas, x):\n",
    "    prediction = []\n",
    "    for index, xi in x.iterrows():\n",
    "        pred_row = []\n",
    "        for theta in thetas:\n",
    "            sig = sigmoid(xi @ theta)\n",
    "            pred_row.append(sig)\n",
    "        prediction.append(np.argmax(pred_row))\n",
    "    \n",
    "    return [classes[p] for p in prediction]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive methods\n",
    "\n",
    "def std(numbers):\n",
    "    avg = np.mean(numbers)\n",
    "    variance = sum([(x-avg)**2 for x in numbers]) / float(len(numbers)-1)\n",
    "    return math.sqrt(variance)\n",
    "def summarize_dataset(dataframe):\n",
    "    summaries = [(np.mean(dataframe[column]), std(dataframe[column]), dataframe[column].shape[0]) for column in dataframe]\n",
    "    del(summaries[-1])\n",
    "    return summaries\n",
    "\n",
    "def pdf(x, mean, stdev):\n",
    "    try:\n",
    "        exponent = math.exp(-((x-mean)**2 / (2 * stdev**2 )))\n",
    "        return (1 / (math.sqrt(2 * math.pi) * stdev)) * exponent\n",
    "    except ZeroDivisionError:\n",
    "        return 1\n",
    "    \n",
    "def calculate_class_probabilities(summaries, row):\n",
    "    total_rows = sum([summaries[label][0][2] for label in summaries])\n",
    "    probabilities = dict()\n",
    "    for class_value, class_summaries in summaries.items():\n",
    "#         print(class_summaries)\n",
    "        probabilities[class_value] = summaries[class_value][0][2]/float(total_rows)\n",
    "        for i in range(len(class_summaries)):\n",
    "            mean, stdev, _ = class_summaries[i]\n",
    "            probabilities[class_value] *= pdf(row[i], mean, stdev)\n",
    "    return probabilities\n",
    "\n",
    "def do_naive_bayes(dataset):\n",
    "    data_group = dataset.groupby(original_df.iloc[:,-1])\n",
    "    summary = summarize_dataset(dataset)\n",
    "    summaries_by_class = {}\n",
    "\n",
    "    for key in data_group.groups.keys():\n",
    "        dataframe = data_group.get_group(key)\n",
    "        summaries_by_class[key] = summarize_dataset(dataframe)\n",
    "        \n",
    "        \n",
    "    error_count = 0\n",
    "\n",
    "    for i,rows in dataset.iterrows():\n",
    "#         print(rows)\n",
    "        class_val = original_df.iloc[i][64]\n",
    "        probabilities = calculate_class_probabilities(summaries_by_class, rows)\n",
    "        largest_probable_class = max(probabilities.items(), key=operator.itemgetter(1))[0]\n",
    "        error_count = error_count + ( 0 if class_val == largest_probable_class else 1)\n",
    "        \n",
    "    return error_count / float(dataset.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic 80-20\n",
    "# train_data_count = int(.8 * len(df)) \n",
    "# train_test_data = df\n",
    "# train_data = train_test_data.iloc[0: train_data_count]\n",
    "# test_data = train_test_data.drop(train_test_data.index[0: train_data_count])\n",
    "# test_classes = test_data.iloc[:, -1]\n",
    "# train_classes = train_data.iloc[:, -1]\n",
    "# train_data.shape, test_data.shape\n",
    "\n",
    "# classes = np.unique(train_classes)\n",
    "# thetas, costs = fit(train_data, train_classes)\n",
    "\n",
    "# train_predicted_value = predict(classes, thetas, train_data)\n",
    "# train_error_count = sum(train_predicted_value != train_classes)\n",
    "# print(\"Train error {0:.3f}%\".format(train_error_count/len(train_predicted_value)*100))\n",
    "# test_predicted_value = predict(classes, thetas, test_data)\n",
    "# test_error_count = sum(test_predicted_value != test_classes)\n",
    "# print(\"Test error {0:.3f}%\".format(test_error_count/len(test_predicted_value)*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hasan/Installations/miniconda3/envs/AML/lib/python3.7/site-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "/home/hasan/Installations/miniconda3/envs/AML/lib/python3.7/site-packages/ipykernel_launcher.py:14: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error 7.778\n"
     ]
    }
   ],
   "source": [
    "# Naive bayes 80-20\n",
    "\n",
    "num_train = int(.8 * len(original_df))  # 80/20 train/test split\n",
    "train_test_data = original_df\n",
    "train_data = train_test_data.iloc[0: num_train]\n",
    "test_data = train_test_data.drop(train_test_data.index[0: num_train])\n",
    "\n",
    "test_error = do_naive_bayes(test_data)\n",
    "# train_error = do_naive_bayes(train_data)\n",
    "\n",
    "print(\"Test error {0:.3f}\".format(test_error*100))\n",
    "# print(\"Train error {0:.3f}\".format(train_error*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  0\n",
      "Logistic Train error 2.226%\n",
      "Logistic Test error 6.111%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:14: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Test error  2.222\n",
      "Naive Bayes Train error  7.978\n",
      "Iteration  1\n",
      "Logistic Train error 0.804%\n",
      "Logistic Test error 5.556%\n",
      "Naive Bayes Test error  0.556\n",
      "Naive Bayes Train error  9.524\n",
      "Iteration  2\n",
      "Logistic Train error 1.237%\n",
      "Logistic Test error 11.111%\n",
      "Naive Bayes Test error  4.444\n",
      "Naive Bayes Train error  8.967\n",
      "Iteration  3\n",
      "Logistic Train error 0.866%\n",
      "Logistic Test error 2.778%\n",
      "Naive Bayes Test error  1.667\n",
      "Naive Bayes Train error  8.967\n",
      "Iteration  4\n",
      "Logistic Train error 0.557%\n",
      "Logistic Test error 3.889%\n",
      "Naive Bayes Test error  0.556\n",
      "Naive Bayes Train error  9.029\n",
      "Iteration  5\n",
      "Logistic Train error 0.680%\n",
      "Logistic Test error 1.667%\n",
      "Naive Bayes Test error  1.667\n",
      "Naive Bayes Train error  9.338\n",
      "Iteration  6\n",
      "Logistic Train error 0.742%\n",
      "Logistic Test error 2.222%\n",
      "Naive Bayes Test error  1.667\n",
      "Naive Bayes Train error  9.400\n",
      "Iteration  7\n",
      "Logistic Train error 0.618%\n",
      "Logistic Test error 3.333%\n",
      "Naive Bayes Test error  0.556\n",
      "Naive Bayes Train error  9.091\n",
      "Iteration  8\n",
      "Logistic Train error 0.495%\n",
      "Logistic Test error 10.000%\n",
      "Naive Bayes Test error  5.000\n",
      "Naive Bayes Train error  7.978\n",
      "Iteration  9\n",
      "Logistic Train error 0.679%\n",
      "Logistic Test error 5.085%\n",
      "Naive Bayes Test error  2.260\n",
      "Naive Bayes Train error  8.272\n"
     ]
    }
   ],
   "source": [
    "#10 fold cross validation\n",
    "fold = 10\n",
    "ratio = 1. / fold\n",
    "index_at = 0\n",
    "length = df.shape[0]\n",
    "test_data_size = math.ceil(length * ratio)\n",
    "\n",
    "error_array = []\n",
    "\n",
    "for k in range(fold):\n",
    "    print(\"Iteration \", k)\n",
    "    train_test_data = original_df\n",
    "    train_data = {}\n",
    "    test_data = {}\n",
    "\n",
    "    test_data = train_test_data.iloc[index_at: index_at + test_data_size]\n",
    "    train_data = train_test_data.drop(df.index[index_at: index_at + test_data_size])\n",
    "    test_classes = test_data.iloc[:, -1]\n",
    "    train_classes = train_data.iloc[:, -1]\n",
    "    \n",
    "    classes = np.unique(train_classes)\n",
    "    thetas, costs = fit(train_data, train_classes)\n",
    "    \n",
    "    train_predicted_value = predict(classes, thetas, train_data)\n",
    "    train_error_count = sum(train_predicted_value != train_classes)\n",
    "    print(\"Logistic Train error {0:.3f}%\".format(train_error_count/len(train_predicted_value)*100))\n",
    "    test_predicted_value = predict(classes, thetas, test_data)\n",
    "    test_error_count = sum(test_predicted_value != test_classes)\n",
    "    print(\"Logistic Test error {0:.3f}%\".format(test_error_count/len(test_predicted_value)*100))\n",
    "    \n",
    "    logistic_train_error =  \"{0:.3f}\".format(train_error_count/len(train_predicted_value)*100)\n",
    "    logistic_test_error =  \"{0:.3f}\".format(test_error_count/len(test_predicted_value)*100)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #naive bayes\n",
    "    \n",
    "    bayes_test_error = \"{0:.3f}\".format(do_naive_bayes(test_data)*100)\n",
    "    bayes_train_error = \"{0:.3f}\".format(do_naive_bayes(train_data)*100)\n",
    "    \n",
    "    \n",
    "    print(\"Naive Bayes Test error \", bayes_test_error)\n",
    "    print(\"Naive Bayes Train error \", bayes_train_error)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    fold_error_array = [logistic_train_error,logistic_test_error,bayes_test_error,bayes_train_error ]\n",
    "\n",
    "    error_array.append(fold_error_array)\n",
    "    \n",
    "    \n",
    "    index_at = index_at + test_data_size\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Train error(%)</th>\n",
       "      <th>Logistic Test error(%)</th>\n",
       "      <th>Naive Bayes Train error(%)</th>\n",
       "      <th>Naive Bayes Test error(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.226</td>\n",
       "      <td>6.111</td>\n",
       "      <td>2.222</td>\n",
       "      <td>7.978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.804</td>\n",
       "      <td>5.556</td>\n",
       "      <td>0.556</td>\n",
       "      <td>9.524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.237</td>\n",
       "      <td>11.111</td>\n",
       "      <td>4.444</td>\n",
       "      <td>8.967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.866</td>\n",
       "      <td>2.778</td>\n",
       "      <td>1.667</td>\n",
       "      <td>8.967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.557</td>\n",
       "      <td>3.889</td>\n",
       "      <td>0.556</td>\n",
       "      <td>9.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.680</td>\n",
       "      <td>1.667</td>\n",
       "      <td>1.667</td>\n",
       "      <td>9.338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.742</td>\n",
       "      <td>2.222</td>\n",
       "      <td>1.667</td>\n",
       "      <td>9.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.618</td>\n",
       "      <td>3.333</td>\n",
       "      <td>0.556</td>\n",
       "      <td>9.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.495</td>\n",
       "      <td>10.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>7.978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.679</td>\n",
       "      <td>5.085</td>\n",
       "      <td>2.260</td>\n",
       "      <td>8.272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Logistic Train error(%) Logistic Test error(%) Naive Bayes Train error(%)  \\\n",
       "1                    2.226                  6.111                      2.222   \n",
       "2                    0.804                  5.556                      0.556   \n",
       "3                    1.237                 11.111                      4.444   \n",
       "4                    0.866                  2.778                      1.667   \n",
       "5                    0.557                  3.889                      0.556   \n",
       "6                    0.680                  1.667                      1.667   \n",
       "7                    0.742                  2.222                      1.667   \n",
       "8                    0.618                  3.333                      0.556   \n",
       "9                    0.495                 10.000                      5.000   \n",
       "10                   0.679                  5.085                      2.260   \n",
       "\n",
       "   Naive Bayes Test error(%)  \n",
       "1                      7.978  \n",
       "2                      9.524  \n",
       "3                      8.967  \n",
       "4                      8.967  \n",
       "5                      9.029  \n",
       "6                      9.338  \n",
       "7                      9.400  \n",
       "8                      9.091  \n",
       "9                      7.978  \n",
       "10                     8.272  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_df = pd.DataFrame(error_array, columns = [\"Logistic Train error(%)\", \"Logistic Test error(%)\", \"Naive Bayes Train error(%)\", \"Naive Bayes Test error(%)\"], index=list(range(1,11)))\n",
    "error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
